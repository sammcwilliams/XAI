==============
Shapley Values
==============

Usage
-----

The Shapley value is a technique brought in from game theory that treats each instance as a player, and treats the prediction as the payoff.

In essence what it does is it looks at how each feature may contribute to the prediction in relation to the average, by iterating through and permuting
features. After analysing the training data in this way, the instances you pass to it can be explained as features causing deviations from the average.

For detail, see this `page <https://christophm.github.io/interpretable-ml-book/shapley.html>`_

Calculation
^^^^^^^^^^^

.. code-block::

    shapley_values, expected = xai.shap.shapley_kernel(test_x[:50])


By passing the first 50 instances in the test set, the function will return both the shapley values for these 50 instances and the 
expected value(s) (the average).

If you're working with a classification problem, the number of classes will indicate the shape of the returned variables. If there are 3 classes
then the shapley values will take the shape (3, num_instances) and the expected values (3,). Intuitively this means that for each class,
you are supposing the features of an instance take the given values, and the results show how much each feature value would contribute if 
the model had predicted that class.

For regression the shapley values will take the shape (num_instances,) and the expected value will be a float.

Plotting
^^^^^^^^

Plotting the shapley values of an instance requires the values themselves, the expected value (of that class if necessary) and a filename. Optionally
you can also pass the feature names too, which will serve as annotations for the plot.

.. code-block::

    xai.shap.plot_shapley(shapley_values[0], expected, "test_data_shapley_plot.png", feature_names)


Since the shap subpackage doesn't have functionality for plotting multiple figures in matplotlib, you can only plot one instance at a time.
This is easily mitigated with a loop.

.. code-block::

    for i in range(len(shapley_values)):
        xai.shap.plot_shapley(shapley_values[i], expected, "test_data_shapley_plot{0}.png".format(i), feature_names)


Looping is also relevant if you wish to look at every class prediction.

.. code-block::

    for i in range(len(shapley_values)):
        for j in range(xai.n_classes):
            xai.shap.plot_shapley(shapley_values[i][j], expected[j], "test_data_shapley_plot{0}_class{1}.png".format(i,j), feature_names)
            

.. figure:: ../assets/doc_shapley.png
    
    :align: center
    
    Figure 1 : Box plot of the Shapley values associated with each feature.

The image above shows that for a prediction of Class 2, the likelihood that the model predicts this class given the features
increases a little bit from the average prediction because of the sepal width, and decreases the chances of predicting Class 2 due to every other feature - resulting in zero chance of the instance 
being in Class 2.

Requisites
----------

blah blah blah

Accepted Data
-------------

blah blah blah

Accepted Models
---------------

blah blah blah

Dimensionality
--------------

blah blah blah

Caveats
-------

Is very computationally expensive.

Output interpretation
---------------------

Just look bro
